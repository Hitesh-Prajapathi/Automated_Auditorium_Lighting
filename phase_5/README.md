# ğŸ¬ PHASE 5: Simulation & Visualization
**"The Lighting Playback Engine"**

* **Status**: âœ… COMPLETED  
* **Owner**: Friend A  
* **Version**: 1.0 (Demo Ready)

---

## ğŸš€ Executive Summary
Phase 5 is the **Visual Output Layer** of the Automated Auditorium Lighting system. It takes the abstract "Lighting Intent" (decisions made by Phase 4) and turns them into a convincing, time-based 3D visualization.

It is designed to be **dumb, fast, and beautiful**. It does not make decisions; it simply executes orders with perfect timing.

---

## ğŸ•¹ï¸ Quick Start (Run the Demo)

1. **Install Dependencies** (if not already done):
   ```bash
   pip install -r requirements.txt
   ```

2. **Start the Playback Server**:
   ```bash
   python3 -m phase_5.server
   ```

3. **Open Visualization**:
   Go to `http://localhost:8000` in your browser.

   * **Play**: Starts the timeline.
   * **Pause**: Freezes time (lights hold state).
   * **Seek**: Click the timeline bar to jump.

---

## ğŸ—ï¸ Architecture & Modules

The system uses a strict **Unidirectional Data Flow**:

```mermaid
Phase 4 (JSON) â†’ Playback Engine â†’ Scene Renderer â†’ Adapter â†’ WebSocket â†’ Three.js
```

### 1. ğŸ§  Playback Engine (`playback_engine.py`)
*   **Role**: The Timeline Controller.
*   **Duty**: Manages `start_time`, `elapsed_time`, and transitions.
*   **Transition Logic**: Strictly **Linear Interpolation**. No magic curves.
*   **Guardrail**: Assumes all inputs are **valid**. Does not validate schema.

### 2. ğŸ¨ Scene Renderer (`scene_renderer.py`)
*   **Role**: The State Keeper.
*   **Duty**: Knows the *current* intensity and color of every group.
*   **Feature**: Pause-safe. You can query it 100 times a second and it just reports `now`.
*   **Logic**: "Dumb" container. Doesn't know about time, only "this light is 50%".

### 3. ğŸ”Œ Three.js Adapter (`threejs_adapter.py`)
*   **Role**: The Translator.
*   **Duty**: Converts logical groups (`front_wash`) into virtual 3D coordinates (`x:0, y:10, z:5`).
*   **Disclaimer**: **Positions are illustrative only.** They do not represent the real physical auditorium (Phase 3).

### 4. ğŸ­ Color Utilities (`color_utils.py`)
*   **Role**: The Interpreter.
*   **Duty**: Maps semantic words (`warm_amber`, `cool_blue`) to hex codes (`#FFB347`, `#4A90E2`).
*   **Polish**: Ensures the demo looks premium, avoiding generic RGB colors.

### 5. ğŸ“¡ Server & Frontend (`server.py` & `static/index.html`)
*   **Server**: FastAPI + WebSocket. Beams state at **Max 30fps**.
*   **Frontend**: Three.js WebGL renderer. using Volumetric Spotlights for realistic beam effects.

---

## ğŸ›¡ï¸ "Rules of Engagement" (For Friend A)

1. **No AI Here**: Phase 5 never calls an LLM or RAG. It strictly renders JSON.
2. **No Hardware**: Phase 5 never outputs DMX or OSC. That is Phase 8.
3. **No Fixing**: If Phase 4 says "Make it dark," Phase 5 makes it dark. It does not "improve" bad designs.
4. **Valid Inputs Only**: Phase 5 crashes (gracefully) on bad input. Validation belongs upstream.

---

## ğŸ”— How to Connect Phase 4 (Next Steps)

Currently, the server runs on `DEMO_DATA` defined in `server.py`.

**To switch to Real AI Mode:**
1. Import `server.py` in the Phase 6 Orchestrator.
2. Call `engine.load_instructions(real_phase_4_json)`.
3. The demo will instantly visualize the AI's output.

---
*Generated by Antigravity (Phase 5 Architect)*
